# -*- coding: utf-8 -*-
"""
Created at: 17.07.2025
@author: marteszibellina
Filename: routes
App: ~/Dev/Ollama/ollama-flask/app/routes.py
"""

import json
import logging
from datetime import datetime
from typing import Dict, List, Optional

import ollama
from flask import Blueprint, jsonify, request, session

from app import db
from app.models import Conversation

bp = Blueprint("main", __name__)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞
logger = logging.getLogger("ollama_thoughts")
logger.setLevel(logging.INFO)


class ThoughtLoggerFormatter(logging.Formatter):
    """–ö–∞—Å—Ç–æ–º–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç—Ç–µ—Ä –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –º—ã—Å–ª–µ–π"""

    def format(self, record):
        thought_types = {
            "user_input": "üë§: ",
            "system": "‚öôÔ∏è: ",
            "thinking": "üí≠: ",
            "response": "üó®Ô∏è: ",
            "error": "‚ùå: ",
        }
        if hasattr(record, "thought_type"):
            prefix = thought_types.get(record.thought_type, "")
            return f"[{datetime.now().strftime('%H:%M:%S')}] {prefix}{record.msg}"
        return super().format(record)


# –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
handler = logging.StreamHandler()
handler.setFormatter(ThoughtLoggerFormatter())
logger.addHandler(handler)


def log_thought(thought_type: str, message: str):
    """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å —Ç–∏–ø–æ–º –º—ã—Å–ª–∏"""
    extra = {"thought_type": thought_type}
    logger.info(message, extra=extra)


def extract_content(response) -> str:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏–∑ –æ—Ç–≤–µ—Ç–∞ Ollama"""
    if hasattr(response, "message") and hasattr(response.message, "content"):
        return response.message.content
    elif isinstance(response, dict):
        return response.get("message", {}).get("content", str(response))
    return str(response)


def prepare_messages(prompt: str, conversation_history: List[Dict]) -> List[Dict]:
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –º–æ–¥–µ–ª–∏ —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
    messages = []

    # –°–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    system_msg = {
        "role": "system",
        "content": '–û—Ç–≤–µ—á–∞–π –ø—Ä–æ—Å—Ç–æ, –±–µ–∑ —Ñ–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç–µ–π, –º–æ–∂–Ω–æ –Ω–∞ "—Ç—ã". –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–π Markdown.',
    }
    messages.append(system_msg)
    log_thought("system", f"–°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç: {system_msg['content'][:50]}...")

    # –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞
    if conversation_history:
        log_thought(
            "thinking", f"–ó–∞–≥—Ä—É–∂–∞—é –∏—Å—Ç–æ—Ä–∏—é ({len(conversation_history)} —Å–æ–æ–±—â–µ–Ω–∏–π)"
        )
        for msg in conversation_history[-10:]:
            messages.append({"role": "user", "content": msg["user"]})
            messages.append({"role": "assistant", "content": msg["ai"]})
            log_thought("context", f"{msg['user'][:30]}... ‚Üí {msg['ai'][:30]}...")

    # –¢–µ–∫—É—â–∏–π –∑–∞–ø—Ä–æ—Å
    messages.append({"role": "user", "content": prompt})
    log_thought("thinking", f"–î–æ–±–∞–≤–ª–µ–Ω —Ç–µ–∫—É—â–∏–π –∑–∞–ø—Ä–æ—Å ({len(prompt)} —Å–∏–º–≤–æ–ª–æ–≤)")

    return messages


def generate_ai_response(
    prompt: str, conversation_history: Optional[List[Dict]] = None
) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –ø–æ–ª–Ω—ã–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º –ø—Ä–æ—Ü–µ—Å—Å–∞"""
    try:
        # –õ–æ–≥–∏—Ä—É–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        log_thought("user_input", prompt[:200] + ("..." if len(prompt) > 200 else ""))

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        messages = prepare_messages(prompt, conversation_history or [])

        log_thought("thinking", "–ù–∞—á–∏–Ω–∞—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –æ—Ç–≤–µ—Ç–∞...")

        # –í–∞—Ä–∏–∞–Ω—Ç 1: –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –∫–ª–∏–µ–Ω—Ç Ollama
        try:
            log_thought("system", "–ò—Å–ø–æ–ª—å–∑—É—é Ollama API (–º–æ–¥–µ–ª—å: gemma3n)")
            response = ollama.chat(
                model="gemma3n",
                messages=messages,
                options={"temperature": 0.7, "num_predict": 4096},
                stream=False,
            )

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞
            result = extract_content(response)
            log_thought(
                "response",
                f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –æ—Ç–≤–µ—Ç ({len(result)} —Å–∏–º–≤–æ–ª–æ–≤): {result[:100]}...",
            )
            return result

        except Exception as e:
            log_thought("error", f"Ollama API: {str(e)}")
            raise

    except Exception as e:
        log_thought("error", f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {str(e)}")
        return f"–û—à–∏–±–∫–∞: {str(e)}"


@bp.route("/chat", methods=["POST"])
def chat():
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —á–∞—Ç-–∑–∞–ø—Ä–æ—Å–æ–≤ —Å –ø–æ–ª–Ω—ã–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
    data = request.get_json()
    user_input = data.get("message", "").strip()

    if not user_input:
        log_thought("error", "–ü—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å")
        return jsonify({"error": "–ü—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å"}), 400

    try:
        # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
        convs = (
            Conversation.query.filter_by(session_id=session["session_id"])
            .order_by(Conversation.timestamp.desc())
            .limit(10)
            .all()
        )

        history = [{"user": c.user_input, "ai": c.ai_response} for c in reversed(convs)]

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
        ai_response = generate_ai_response(user_input, history)

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        conv = Conversation(
            session_id=session["session_id"],
            user_input=user_input,
            ai_response=ai_response,
        )
        db.session.add(conv)
        db.session.commit()

        log_thought("system", "–î–∏–∞–ª–æ–≥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –±–∞–∑—É")
        return jsonify(
            {"response": ai_response, "timestamp": datetime.utcnow().isoformat()}
        )

    except Exception as e:
        log_thought("error", f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}")
        return jsonify({"error": str(e)}), 500


@bp.route("/", methods=["GET", "POST"])
def index():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞"""
    if "session_id" not in session:
        session["session_id"] = str(uuid.uuid4())
    return render_template("index.html")


@bp.route("/history", methods=["GET"])
def get_history():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π"""
    if "session_id" not in session:
        return jsonify([])

    conversations = (
        Conversation.query.filter_by(session_id=session["session_id"])
        .order_by(Conversation.timestamp.asc())
        .all()
    )

    history = [
        {
            "user": conv.user_input,
            "ai": conv.ai_response,
            "time": conv.timestamp.isoformat(),
        }
        for conv in conversations
    ]

    return jsonify({"history": history})


@bp.route("/clear", methods=["POST"])
def clear_history():
    """–û—á–∏—Å—Ç–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ —Ç–µ–∫—É—â–µ–π —Å–µ—Å—Å–∏–∏"""
    Conversation.query.filter_by(session_id=session["session_id"]).delete()
    db.session.commit()
    return jsonify({"status": "success"})
